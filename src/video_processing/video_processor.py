import json
import subprocess
import os
from typing import List, Dict, Optional
# MoviePy lazy import (yavaÅŸ yÃ¼klenebilir)
# from moviepy import VideoFileClip  # Lazy import
# FaceTracker lazy import (MediaPipe yÃ¼klemesi yavaÅŸ olabilir)
# from src.face_tracking.face_tracker import FaceTracker  # Lazy import
from src.video_effects.zoom_effect import ZoomEffectCalculator


class VideoProcessor:
    """
    FFmpeg ile video iÅŸleme orchestrator
    EB-2: Auto Camera Zoom uygular
    """
    
    def __init__(self,
                 energy_threshold: float = 0.75,
                 face_sample_rate: float = 1.0):  # Default: Her 1 saniyede bir frame (hÄ±z/doÄŸruluk dengesi)
        # Lazy load: FaceTracker'Ä± sadece gerektiÄŸinde yÃ¼kle (MediaPipe yÃ¼klemesi yavaÅŸ olabilir)
        self._face_sample_rate = face_sample_rate
        self._face_tracker = None
        self.zoom_calculator = ZoomEffectCalculator(energy_threshold=energy_threshold)
    
    @property
    def face_tracker(self):
        """Lazy load FaceTracker (MediaPipe sadece gerektiÄŸinde yÃ¼klenir)"""
        if self._face_tracker is None:
            print("Initializing FaceTracker (loading MediaPipe - this may take a moment)...")
            # Lazy import: Sadece gerektiÄŸinde MediaPipe yÃ¼kle
            from src.face_tracking.face_tracker import FaceTracker
            self._face_tracker = FaceTracker(sample_rate=self._face_sample_rate)
            print("FaceTracker initialized")
        return self._face_tracker
    
    def get_video_info(self, video_path: str) -> Dict:
        """Video bilgilerini al"""
        from moviepy import VideoFileClip  # Lazy import
        video = VideoFileClip(video_path)
        info = {
            "width": video.w,
            "height": video.h,
            "fps": video.fps,
            "duration": video.duration
        }
        video.close()
        return info
    
    def apply_zoom_effects(self,
                          video_path: str,
                          timeline_path: str,
                          output_path: str,
                          face_positions_path: Optional[str] = None) -> str:
        """
        Timeline JSON'u okuyup zoom efektlerini uygular
        
        Args:
            video_path: Input video file
            timeline_path: Emotion timeline JSON path
            output_path: Output video path
            face_positions_path: Optional cached face positions JSON
        """
        print(f"\n{'='*60}")
        print("EB-2: Applying Auto Camera Zoom Effects")
        print(f"{'='*60}\n")
        
        # 1. Video bilgileri
        print("STEP 1: Getting video info...")
        video_info = self.get_video_info(video_path)
        print(f"Video: {video_info['width']}x{video_info['height']}, "
              f"{video_info['fps']:.2f} fps, {video_info['duration']:.2f}s")
        
        # 2. Timeline yÃ¼kle
        print("\nSTEP 2: Loading emotion timeline...")
        with open(timeline_path, 'r', encoding='utf-8') as f:
            timeline = json.load(f)
        print(f"Loaded {len(timeline)} timeline segments")
        
        # 3. Face tracking
        print("\nSTEP 3: Face tracking...")
        if face_positions_path and os.path.exists(face_positions_path):
            print(f"Loading cached face positions from: {face_positions_path}")
            face_positions = self.face_tracker.load_face_positions(face_positions_path)
        else:
            face_positions = self.face_tracker.track_faces_in_video(video_path)
            if face_positions_path:
                self.face_tracker.save_face_positions(face_positions, face_positions_path)
        
        # 4. Zoom efektlerini hesapla
        print("\nSTEP 4: Calculating zoom effects...")
        zoom_segments = self.zoom_calculator.process_timeline_segments(
            timeline,
            face_positions,
            video_info["width"],
            video_info["height"],
            video_info["fps"]
        )
        
        print(f"Found {len(zoom_segments)} segments for zoom effect")
        if zoom_segments:
            print(f"Zoom range: {min(s['zoom_factor'] for s in zoom_segments):.2f} - "
                  f"{max(s['zoom_factor'] for s in zoom_segments):.2f}")
        
        # 5. FFmpeg filter chain oluÅŸtur
        print("\nSTEP 5: Building FFmpeg filter chain...")
        filter_complex = self.build_filter_complex(zoom_segments, video_info, timeline)
        
        # 6. FFmpeg komutu Ã§alÄ±ÅŸtÄ±r
        print("\nSTEP 6: Rendering video with FFmpeg...")
        self.render_video(video_path, output_path, filter_complex, video_info)
        
        print(f"\n{'='*60}")
        print(f"âœ… Video rendered: {output_path}")
        print(f"{'='*60}\n")
        
        return output_path
    
    def build_filter_complex(self, 
                           zoom_segments: List[Dict],
                           video_info: Dict,
                           timeline: List[Dict]) -> str:
        """
        FFmpeg filter_complex string'i oluÅŸturur
        
        Segment bazlÄ± dinamik zoom:
        - YÃ¼ksek enerji â†’ zoom in (yakÄ±nlaÅŸma)
        - DÃ¼ÅŸÃ¼k enerji â†’ zoom out (uzaklaÅŸma)
        - Timeline'daki her segment iÃ§in farklÄ± zoom faktÃ¶rÃ¼
        """
        if not timeline:
            return ""  # Timeline yok
        
        width = video_info['width']
        height = video_info['height']
        fps = video_info['fps']
        
        # Timeline'daki TÃœM segmentler iÃ§in zoom faktÃ¶rÃ¼ hesapla
        # Ã–NEMLÄ°: Energy deÄŸerlerini normalize et (JSON'daki energy 0.0-0.55 arasÄ± olabilir)
        # Ã–nce max energy'yi bul
        all_energies = [seg.get("energy", 0.0) for seg in timeline]
        max_energy = max(all_energies) if all_energies else 1.0
        min_energy = min(all_energies) if all_energies else 0.0
        energy_range = max_energy - min_energy if max_energy > min_energy else 1.0
        
        print(f"Energy range in timeline: {min_energy:.2f} - {max_energy:.2f}")
        
        segment_zooms = []
        
        for segment in timeline:
            energy = segment.get("energy", 0.0)
            start_time = segment["start"]
            end_time = segment["end"]
            
            # Energy'yi normalize et (0.0-1.0 aralÄ±ÄŸÄ±na)
            if energy_range > 0:
                normalized_energy = (energy - min_energy) / energy_range
            else:
                normalized_energy = 0.0
            
            # Normalize edilmiÅŸ energy'ye gÃ¶re zoom faktÃ¶rÃ¼ hesapla
            # DÃ¼ÅŸÃ¼k enerji (0.0-0.3) â†’ zoom out (0.95) - daha gÃ¶rÃ¼nÃ¼r uzaklaÅŸma
            # Orta enerji (0.3-0.6) â†’ zoom 1.0-1.15 - daha gÃ¶rÃ¼nÃ¼r zoom
            # YÃ¼ksek enerji (0.6-1.0) â†’ zoom 1.15-1.25 - Ã§ok daha gÃ¶rÃ¼nÃ¼r zoom
            if normalized_energy < 0.3:
                zoom_factor = 0.95  # Zoom out (uzaklaÅŸma) - %5 zoom out
            elif normalized_energy < 0.6:
                # Orta enerji: 0.3-0.6 â†’ zoom 1.0-1.15
                zoom_factor = 1.0 + (normalized_energy - 0.3) * 0.5  # 0.0-0.15 range
            else:
                # YÃ¼ksek enerji: 0.6-1.0 â†’ zoom 1.15-1.25
                zoom_factor = 1.15 + (normalized_energy - 0.6) * 0.25  # 0.15-0.25 range
            
            segment_zooms.append({
                "start": start_time,
                "end": end_time,
                "zoom": zoom_factor,
                "energy": energy
            })
        
        # FFmpeg expression oluÅŸtur: segment bazlÄ± zoom
        # Format: if(between(t,start,end),zoom_factor,if(between(t,start2,end2),zoom_factor2,...))
        # Ã–NEMLÄ°: Segment'leri sÄ±ralayÄ±p overlap'leri kaldÄ±rmalÄ±yÄ±z
        if len(segment_zooms) == 0:
            return ""  # Segment yok
        
        # Segment'leri zaman sÄ±rasÄ±na gÃ¶re sÄ±rala
        sorted_segments = sorted(segment_zooms, key=lambda x: x['start'])
        
        # Overlap'leri kaldÄ±r ve segment'leri birleÅŸtir
        # Ã–nce overlap'leri kaldÄ±r: EÄŸer iki segment overlap ediyorsa, zoom faktÃ¶rÃ¼ yÃ¼ksek olanÄ± kullan
        cleaned_segments = []
        for seg in sorted_segments:
            # Bu segment'i eklemeden Ã¶nce, mevcut segment'lerle overlap var mÄ± kontrol et
            should_add = True
            for i, existing in enumerate(cleaned_segments):
                # Overlap kontrolÃ¼
                if not (seg['end'] <= existing['start'] or seg['start'] >= existing['end']):
                    # Overlap var! YÃ¼ksek zoom faktÃ¶rÃ¼ne sahip olanÄ± kullan
                    if seg['zoom'] > existing['zoom']:
                        # Mevcut segment'i kaldÄ±r, yeni segment'i ekle
                        cleaned_segments[i] = seg.copy()
                    should_add = False
                    break
            
            if should_add:
                cleaned_segments.append(seg.copy())
        
        # AynÄ± zoom faktÃ¶rÃ¼ne sahip komÅŸu segment'leri birleÅŸtir
        merged_segments = []
        current_seg = None
        
        for seg in sorted(cleaned_segments, key=lambda x: x['start']):
            if current_seg is None:
                current_seg = seg.copy()
            elif (abs(current_seg['zoom'] - seg['zoom']) < 0.001 and 
                  current_seg['end'] >= seg['start'] - 0.1):  # 0.1s tolerance for merging
                # BirleÅŸtir: end time'i gÃ¼ncelle
                current_seg['end'] = max(current_seg['end'], seg['end'])
            else:
                # Yeni segment baÅŸlat
                merged_segments.append(current_seg)
                current_seg = seg.copy()
        
        if current_seg is not None:
            merged_segments.append(current_seg)
        
        # EÄŸer hala Ã§ok fazla segment varsa, sadece en Ã¶nemli olanlarÄ± kullan (max 10 segment)
        if len(merged_segments) > 10:
            # En yÃ¼ksek enerji farkÄ±na sahip segment'leri seÃ§
            merged_segments.sort(key=lambda x: x['energy'], reverse=True)
            merged_segments = merged_segments[:10]
            merged_segments.sort(key=lambda x: x['start'])
        
        # Segment bazlÄ± dinamik zoom iÃ§in FFmpeg'de trim + crop + scale + concat kullanÄ±yoruz
        # crop filter'Ä± nested if() expression'larÄ±nÄ± parse edemiyor
        # Bu yÃ¼zden her segment iÃ§in ayrÄ± trim + crop + scale uygulayÄ±p concat ile birleÅŸtiriyoruz
        
        if len(merged_segments) == 0:
            return ""  # Segment yok
        
        # Segment'leri zaman sÄ±rasÄ±na gÃ¶re sÄ±rala
        merged_segments = sorted(merged_segments, key=lambda x: x['start'])
        
        # Video sÃ¼resini al
        video_duration = video_info.get('duration', 0.0)
        if video_duration <= 0:
            # Timeline'dan video sÃ¼resini tahmin et
            if timeline:
                video_duration = max(seg.get('end', 0.0) for seg in timeline)
            else:
                video_duration = 60.0  # Default 60 saniye
        
        # Face center (ÅŸimdilik video merkezi)
        face_center_x = width / 2
        face_center_y = height / 2
        
        # Default zoom (segment dÄ±ÅŸÄ±ndaki zamanlar iÃ§in)
        default_zoom = 1.0
        
        # TÃ¼m video'yu segment'lere bÃ¶l (segment'ler arasÄ±ndaki boÅŸluklarÄ± da dahil et)
        all_segments = []
        current_time = 0.0
        
        for seg in merged_segments:
            seg_start = seg['start']
            seg_end = seg['end']
            seg_zoom = seg['zoom']
            
            # EÄŸer current_time ile seg_start arasÄ±nda boÅŸluk varsa, default zoom segment'i ekle
            if current_time < seg_start:
                all_segments.append({
                    'start': current_time,
                    'end': seg_start,
                    'zoom': default_zoom,
                    'type': 'default'
                })
            
            # Zoom segment'ini ekle
            all_segments.append({
                'start': seg_start,
                'end': seg_end,
                'zoom': seg_zoom,
                'type': 'zoom'
            })
            
            current_time = seg_end
        
        # Video sonuna kadar default zoom segment'i ekle
        if current_time < video_duration:
            all_segments.append({
                'start': current_time,
                'end': video_duration,
                'zoom': default_zoom,
                'type': 'default'
            })
        
        # Segment sayÄ±sÄ±nÄ± sÄ±nÄ±rla (Ã§ok fazla segment filter'Ä± Ã§ok uzun yapar)
        if len(all_segments) > 20:
            # En yÃ¼ksek zoom farkÄ±na sahip segment'leri seÃ§
            segments_with_diff = []
            for seg in all_segments:
                diff = abs(seg['zoom'] - default_zoom)
                segments_with_diff.append((diff, seg))
            segments_with_diff.sort(reverse=True, key=lambda x: x[0])
            # En Ã¶nemli segment'leri al, ama zaman sÄ±rasÄ±nÄ± koru
            important_segments = [seg for _, seg in segments_with_diff[:15]]
            important_segments.sort(key=lambda x: x['start'])
            all_segments = important_segments
            print(f"âš ï¸  Too many segments, using top {len(all_segments)} segments with highest zoom difference")
        
        # Her segment iÃ§in trim + crop + scale filter'Ä± oluÅŸtur
        filter_parts = []
        output_labels = []
        
        for i, seg in enumerate(all_segments):
            seg_start = seg['start']
            seg_end = seg['end']
            seg_zoom = seg['zoom']
            
            # Crop koordinatlarÄ±nÄ± hesapla
            crop_w = int(width / seg_zoom)
            crop_h = int(height / seg_zoom)
            crop_x = int((width - crop_w) / 2)
            crop_y = int((height - crop_h) / 2)
            
            # Output label
            output_label = f"v{i}"
            output_labels.append(output_label)
            
            # Filter: trim + setpts + crop + scale
            filter_part = (
                f"[0:v]trim=start={seg_start:.3f}:end={seg_end:.3f},"
                f"setpts=PTS-STARTPTS,"
                f"crop={crop_w}:{crop_h}:{crop_x}:{crop_y},"
                f"scale={width}:{height}:flags=lanczos[{output_label}]"
            )
            filter_parts.append(filter_part)
        
        # Concat filter: TÃ¼m segment'leri birleÅŸtir
        concat_inputs = "".join([f"[{label}]" for label in output_labels])
        concat_filter = f"{concat_inputs}concat=n={len(output_labels)}:v=1[outv]"
        
        # TÃ¼m filter'larÄ± birleÅŸtir
        filter_str = ";".join(filter_parts) + ";" + concat_filter
        
        zoom_range = [seg["zoom"] for seg in merged_segments]
        print(f"Segment-based dynamic zoom: {len(all_segments)} segments (merged from {len(segment_zooms)} original)")
        print(f"Zoom range: {min(zoom_range):.2f} - {max(zoom_range):.2f}")
        print(f"Using trim+crop+scale+concat approach with {len(all_segments)} segments")
        print(f"Energy-based: Low energy â†’ zoom out (0.95), High energy â†’ zoom in (1.25)")
        
        # Debug: Filter string uzunluÄŸunu kontrol et
        if len(filter_str) > 5000:
            print(f"âš ï¸  Warning: Filter string is very long ({len(filter_str)} chars), may cause FFmpeg parsing issues")
        
        # Debug: Filter string'in ilk 300 karakterini yazdÄ±r
        print(f"\nğŸ” DEBUG: FFmpeg filter string (first 300 chars):")
        print(f"{filter_str[:300]}...")
        print(f"Total filter string length: {len(filter_str)} chars\n")
        
        return filter_str
    
    def render_video(self, 
                    input_path: str,
                    output_path: str,
                    filter_complex: str,
                    video_info: Dict):
        """FFmpeg ile video render"""
        if not filter_complex:
            # Filter yoksa, video'yu kopyala
            print("No zoom effects to apply, copying video...")
            cmd = [
                "ffmpeg", "-i", input_path,
                "-c", "copy",
                output_path, "-y"
            ]
        else:
            # Use VideoToolbox hardware encoder on macOS for Metal acceleration
            import platform
            use_hardware_encoder = platform.system() == "Darwin"  # macOS
            
            # Segment bazlÄ± dinamik zoom iÃ§in trim+crop+scale+concat kullanÄ±yoruz
            # filter_complex kullanÄ±yoruz Ã§Ã¼nkÃ¼ multiple input/output var
            print("Using software encoder (trim+crop+scale+concat approach)")
            cmd = [
                "ffmpeg", "-i", input_path,
                "-filter_complex", filter_complex,
                "-map", "[outv]",  # Concat output'unu map et (video)
                "-map", "0:a",  # Audio stream'i de map et (SES Ä°Ã‡Ä°N GEREKLÄ°!)
                "-c:v", "libx264",  # Software encoder (daha stabil)
                "-preset", "ultrafast",  # En hÄ±zlÄ± encoding
                "-crf", "28",  # Quality (18-28 arasÄ±, 28 = hÄ±zlÄ± encoding, kabul edilebilir kalite)
                "-threads", "0",  # TÃ¼m CPU core'larÄ± kullan
                "-c:a", "copy",
                output_path, "-y"
            ]
        
        print(f"Running FFmpeg command...")
        print(f"Optimized settings: segment-based dynamic crop+scale, ultrafast preset, CRF 28, threads=0")
        print(f"Estimated: 1-2 min for 60s video (crop+scale is fast)")
        
        # Debug: FFmpeg komutunu yazdÄ±r
        print(f"\nğŸ” DEBUG: FFmpeg command:")
        print(f"  Filter: {filter_complex[:200]}..." if len(filter_complex) > 200 else f"  Filter: {filter_complex}")
        print()
        
        try:
            # Basit yaklaÅŸÄ±m: stderr'i direkt terminal'e yÃ¶nlendir (progress gÃ¶sterir)
            # FFmpeg progress bilgisini stderr'e yazar, bu yÃ¼zden direkt gÃ¶steriyoruz
            result = subprocess.run(
                cmd,
                check=True,
                stderr=None  # stderr'i terminal'e yÃ¶nlendir (progress gÃ¶sterir)
            )
            print("\nâœ… FFmpeg completed successfully")
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ FFmpeg error (return code: {e.returncode})")
            raise


# Usage example
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 4:
        print("Usage: python video_processor.py <video_path> <timeline_path> <output_path> [face_positions_path]")
        sys.exit(1)
    
    video_path = sys.argv[1]
    timeline_path = sys.argv[2]
    output_path = sys.argv[3]
    face_positions_path = sys.argv[4] if len(sys.argv) > 4 else None
    
    processor = VideoProcessor()
    processor.apply_zoom_effects(
        video_path=video_path,
        timeline_path=timeline_path,
        output_path=output_path,
        face_positions_path=face_positions_path
    )

